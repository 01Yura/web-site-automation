<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Local Deployment - Spring Digital Bookstore App</title>
    <link rel="icon" type="image/png" href="../favicon.png" />
    <link rel="stylesheet" href="../assets/styles.css" />
    <script src="../assets/copy-code.js"></script>
    <style>
      ol.main-steps li::marker {
        font-weight: bold;
      }
    </style>
  </head>
  <body>
    <div class="language-switcher">
      <a href="../index.html" class="lang-link">Home</a>
      <span class="lang-separator">|</span>
      <a href="../ru/local-app.html" class="lang-link">RU</a>
      <span class="lang-separator">|</span>
      <a href="local-app.html" class="lang-link active">EN</a>
    </div>

    <div class="card">
      <h1>Local Deployment</h1>
      <ol class="main-steps">
        <li>
          Download the <strong>docker-compose.yml</strong> file from GitHub using
          the link below and run it with the command
          <code>docker-compose up -d</code>.
        </li>
      </ol>

      <p>
        <a
          href="https://github.com/01Yura/backend-spring-digital-bookstore/blob/main/for_local_run_only/docker-compose.yml"
          target="_blank"
          rel="noopener"
          >Download docker-compose.yml from GitHub</a
        ><br />
        On the opened GitHub page, click the button on the right
        <strong>&quot;Download raw file&quot;</strong>.<br />
        Note: this docker-compose file is quite large because I’ve hardcoded all
        ELK, Prometheus and Grafana configs into it, so you don’t need to
        create separate configuration files — everything will start with a
        single command.
      </p>

      <!--
      <div class="code-block copyable">
        <pre><code>services:
  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: kafka-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - spring-library-network
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 2181 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Kafka Broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-broker
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka-broker:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168 # 7 days
      KAFKA_LOG_SEGMENT_BYTES: 1073741824 # 1GB
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # Memory limit for Kafka (heap memory)
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"
    networks:
      - spring-library-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 120s
    restart: unless-stopped

  # Kafka UI - graphical interface for viewing topics and messages
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      kafka:
        condition: service_started
    ports:
      - "8089:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-broker:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      # Authentication via Basic Auth
      AUTH_TYPE: ${KAFKA_UI_AUTH_TYPE:-BASIC}
      SPRING_SECURITY_USER_NAME: ${KAFKA_UI_USERNAME:-admin}
      SPRING_SECURITY_USER_PASSWORD: ${KAFKA_UI_PASSWORD:-admin}
    networks:
      - spring-library-network
    restart: unless-stopped

  # MailHog - SMTP server for email development and testing
  # Web interface: http://localhost:8025
  # SMTP port: 1025
  mailhog:
    image: mailhog/mailhog:latest
    container_name: mailhog_email_server
    ports:
      - "1025:1025" # SMTP port
      - "8025:8025" # Web UI for viewing emails
    networks:
      - spring-library-network
    restart: unless-stopped

  # Analytics Service
  analytics-service:
    image: 01yura/spring-digital-bookstore-analytics-service:elk
    pull_policy: always
    container_name: analytics-service
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8090:8090"
    environment:
      # Kafka Configuration
      KAFKA_BOOTSTRAP_SERVERS: kafka-broker:29092
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka-broker:29092
      KAFKA_CONSUMER_GROUP_ID: analytics-service-group
      SPRING_KAFKA_CONSUMER_GROUP_ID: analytics-service-group
      # Server Configuration
      SERVER_PORT: 8090
      # Logging
      LOGGING_LEVEL_ROOT: INFO
      LOGGING_LEVEL_ORG_APACHE_KAFKA: WARN
      LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_KAFKA: INFO
      LOGGING_LEVEL_ONLINE_ITYURA_ANALYTICS: INFO
      # Aggregation interval
      ANALYTICS_AGGREGATION_INTERVAL_MS: ${ANALYTICS_AGGREGATION_INTERVAL_MS:-60000}
      # ELK Stack settings for sending logs to Logstash
      LOGSTASH_HOST: logstash
      LOGSTASH_PORT: 5000
      LOGSTASH_ENABLED: "true"
    networks:
      - spring-library-network
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:8090/api/analytics/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # React UI application
  ui:
    image: 01yura/spring-digital-library-ui:with_analytics_and_email_without_https_for_local_run
    pull_policy: always
    container_name: spring-digital-bookstore-ui
    ports:
      - "80:80"
    networks:
      - spring-library-network
    depends_on:
      - backend
    restart: unless-stopped

  # PostgreSQL database for local deployment
  postgres:
    image: postgres:16-alpine
    container_name: spring-digital-library-db
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-spring_digital_bookstore}
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-admin}
    ports:
      - "5432:5432"
    volumes:
      # Database data storage on host (for Windows use format C:/path/to/dir)
      - ${POSTGRES_DATA_PATH:-C:/spring-digital-bookstore/postgres_data}:/var/lib/postgresql/data
    networks:
      - spring-library-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d spring_digital_bookstore"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Spring Boot application for local deployment without HTTPS
  backend:
    image: 01yura/spring-digital-bookstore:elk
    pull_policy: always
    container_name: spring-digital-bookstore-app
    environment:
      # Database connection settings
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB:-spring_digital_bookstore}
      SPRING_DATASOURCE_USERNAME: ${SPRING_DATASOURCE_USERNAME:-admin}
      SPRING_DATASOURCE_PASSWORD: ${SPRING_DATASOURCE_PASSWORD:-admin}

      # JPA/Hibernate settings
      SPRING_JPA_DATABASE_PLATFORM: ${SPRING_JPA_DATABASE_PLATFORM:-org.hibernate.dialect.PostgreSQLDialect}
      SPRING_JPA_HIBERNATE_DDL_AUTO: ${SPRING_JPA_HIBERNATE_DDL_AUTO:-update}
      SPRING_JPA_SHOW_SQL: ${SPRING_JPA_SHOW_SQL:-false}
      SPRING_JPA_PROPERTIES_HIBERNATE_FORMAT_SQL: ${SPRING_JPA_PROPERTIES_HIBERNATE_FORMAT_SQL:-true}

      # JWT settings
      JWT_SECRET: ${JWT_SECRET:-my-secret-key-for-jwt-generation}
      JWT_EXPIRATION: ${JWT_EXPIRATION:-300000}
      JWT_REFRESH_EXPIRATION: ${JWT_REFRESH_EXPIRATION:-86400000}

      # Swagger/OpenAPI settings
      SPRINGDOC_API_DOCS_PATH: ${SPRINGDOC_API_DOCS_PATH:-/v3/api-docs}
      SPRINGDOC_SWAGGER_UI_PATH: ${SPRINGDOC_SWAGGER_UI_PATH:-/swagger-ui.html}
      SPRINGDOC_SWAGGER_UI_OPERATIONS_SORTER: ${SPRINGDOC_SWAGGER_UI_OPERATIONS_SORTER:-method}
      SPRINGDOC_SWAGGER_UI_TAGS_SORTER: ${SPRINGDOC_SWAGGER_UI_TAGS_SORTER:-alpha}

      # JVM settings
      JAVA_OPTS: ${JAVA_OPTS:--Xmx512m -Xms512m}

      # Path for storing book images (fixed inside container)
      APP_IMAGES_STORAGE_PATH: /opt/spring-digital-bookstore/pictures
      # Path for storing book PDF files (fixed inside container)
      APP_PDF_STORAGE_PATH: /opt/spring-digital-bookstore/pdf

      # Frontend URL for redirect after payment
      FRONTEND_URL: ${FRONTEND_URL:-http://localhost}

      # Stripe settings
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY:-sk_test_51Sn9eKF06mQasm4mhBSG71Wes6rz09BTuQicIu37oRIw5agFgZuGMGZQk4IeftRm2aQGJXFma5IPwm1iT77WlALs00VDZNJkEL}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET:-test-value}
      STRIPE_SUCCESS_URL: ${STRIPE_SUCCESS_URL:-http://localhost/api/v1/payment/success}
      STRIPE_CANCEL_URL: ${STRIPE_CANCEL_URL:-http://localhost/api/v1/payment/cancel}

      # OpenAI API settings
      OPENAI_API_KEY: ${OPENAI_API_KEY:-test-value}

      # Gemini API settings
      GEMINI_API_KEY: ${GEMINI_API_KEY:-test-value}

      # Kafka Configuration for sending events
      KAFKA_BOOTSTRAP_SERVERS: kafka-broker:29092
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka-broker:29092

      # Telegram settings for sending messages to Telegram Bot
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN:-test-value}
      TELEGRAM_CHAT_ID: ${TELEGRAM_CHAT_ID:-test-value}

      # SMTP settings for sending email via MailHog
      SPRING_MAIL_HOST: mailhog
      SPRING_MAIL_PORT: 1025
      SPRING_MAIL_USERNAME: ${SPRING_MAIL_USERNAME:-}
      SPRING_MAIL_PASSWORD: ${SPRING_MAIL_PASSWORD:-}
      SPRING_MAIL_SMTP_AUTH: ${SPRING_MAIL_SMTP_AUTH:-false}
      SPRING_MAIL_SMTP_STARTTLS_ENABLE: ${SPRING_MAIL_SMTP_STARTTLS_ENABLE:-false}
      SPRING_MAIL_SMTP_SSL_ENABLE: ${SPRING_MAIL_SMTP_SSL_ENABLE:-false}
      SPRING_MAIL_FROM: ${SPRING_MAIL_FROM:-noreply@localhost}

      # Base URL for email verification links (must match the port where backend is available)
      APP_EMAIL_VERIFICATION_BASE_URL: ${APP_EMAIL_VERIFICATION_BASE_URL:-http://localhost}

      # ELK Stack settings for sending logs to Logstash
      LOGSTASH_HOST: logstash
      LOGSTASH_PORT: 5000

      # Enable/disable Logstash (disabled by default in application.properties)
      LOGSTASH_ENABLED: "true"
      # Enable/disable Kafka (disabled by default in application.properties)
      KAFKA_ENABLED: "true"

    ports:
      - "8088:8080"
    volumes:
      # Storing book images in regular directory on host (for Windows use format C:/path/to/dir)
      - ${APP_IMAGES_STORAGE_PATH:-C:/spring-digital-bookstore/pictures}:/opt/spring-digital-bookstore/pictures
      # Storing book PDF files in regular directory on host (for Windows use format C:/path/to/dir)
      - ${APP_PDF_STORAGE_PATH:-C:/spring-digital-bookstore/pdf}:/opt/spring-digital-bookstore/pdf
    networks:
      - spring-library-network
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      mailhog:
        condition: service_started
    restart: unless-stopped

  # Elasticsearch for storing logs
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      # Increase memory to 1GB for stable operation
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      # Disable memory_lock for Windows/Docker (may not work)
      - bootstrap.memory_lock=false
      # Settings for faster operation in dev environment
      - action.auto_create_index=true
      - cluster.routing.allocation.disk.threshold_enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - ${ELASTICSEARCH_DATA_PATH:-C:/spring-digital-bookstore/elasticsearch_data}:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - spring-library-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -f http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=30s || exit 1",
        ]
      interval: 30s
      timeout: 30s
      retries: 10
      start_period: 120s
    restart: unless-stopped

  # Logstash for receiving and processing logs
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - "5000:5000"
      - "5044:5044"
      - "9600:9600"
    environment:
      - "LS_JAVA_OPTS=-Xmx256m -Xms256m"
    command:
      - /bin/bash
      - -c
      - |
        mkdir -p /usr/share/logstash/pipeline /usr/share/logstash/config
        cat > /usr/share/logstash/config/pipelines.yml << 'PIPELINES_EOF'
        # Pipeline configuration for Logstash
        - pipeline.id: main
          path.config: "/usr/share/logstash/pipeline/logstash.conf"
        PIPELINES_EOF
        cat > /usr/share/logstash/config/logstash.yml << 'LOGSTASH_EOF'
        http.host: "0.0.0.0"
        xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch:9200" ]
        LOGSTASH_EOF
        cat > /usr/share/logstash/pipeline/logstash.conf << 'LOGCONF_EOF'
        input {
          tcp {
            port => 5000
            codec => json_lines
          }
        }

        filter {
          # logstash-logback-encoder sends JSON directly via TCP with json_lines codec
          # All fields are already directly available (level, message, service, @timestamp, logger_name, thread_name, etc.)
          
          # Adding metadata for indexing based on service field
          mutate {
            add_field => { "[@metadata][index]" => "%{service}-logs-%{+YYYY.MM.dd}" }
          }
          
          # If service is not defined, use default value
          if ![service] {
            mutate {
              add_field => { "service" => "unknown" }
            }
          }
          
          # Filtering sensitive data (passwords, tokens)
          # Uncomment if you need to mask sensitive data
          # mutate {
          #   gsub => [
          #     "message", "(?i)(password|token|secret|key|api[_-]?key)=[^&\s\"']+", "\1=***",
          #     "message", "(?i)(\"password\"\\s*:\\s*\")([^\"]+)(\")", "\1***\3",
          #     "message", "(?i)(\"token\"\\s*:\\s*\")([^\"]+)(\")", "\1***\3"
          #   ]
          # }
        }

        output {
          elasticsearch {
            hosts => ["elasticsearch:9200"]
            # Dynamic index based on service field
            index => "%{[@metadata][index]}"
            # Or you can use fixed indices:
            # index => "%{service}-logs-%{+YYYY.MM.dd}"
          }
          
          # Fallback to stdout for debugging (optional, can be commented out in production)
          stdout {
            codec => rubydebug
          }
        }
        LOGCONF_EOF
        exec /usr/local/bin/docker-entrypoint
    networks:
      - spring-library-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9600/_node/stats || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      # Increase timeouts for index creation
      - ELASTICSEARCH_REQUEST_TIMEOUT=120000
      # Settings for faster startup
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=changeme-changeme-changeme-changeme
      - XPACK_REPORTING_ENCRYPTIONKEY=changeme-changeme-changeme-changeme
      - XPACK_SECURITY_ENCRYPTIONKEY=changeme-changeme-changeme-changeme
    networks:
      - spring-library-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 300s
    restart: unless-stopped

networks:
  spring-library-network:
    driver: bridge</code></pre>
      </div>
      -->
      <p>
        Frontend will be available at
        <a href="http://localhost" target="_blank" rel="noopener"
          >http://localhost</a
        >
      </p>
      <p>
        Swagger at
        <a
          href="http://localhost:8088/swagger-ui/index.html"
          target="_blank"
          rel="noopener"
          >http://localhost:8088/swagger-ui/index.html</a
        >
      </p>
      <p>
        Kafka UI at:
        <a href="http://localhost:8089" target="_blank" rel="noopener"
          >http://localhost:8089</a
        >
        (admin, admin)
      </p>
      <p>
        MailHog (web interface for viewing sent emails and registration confirmation) at:
        <a href="http://localhost:8025" target="_blank" rel="noopener"
          >http://localhost:8025</a
        >
      </p>
      <p>
        <strong>Kibana</strong> (web interface for viewing logs) at:
        <a href="http://localhost:5601" target="_blank" rel="noopener"
          >http://localhost:5601</a
        ><br />
        To display logs in Kibana, you need to configure indices (create so-called Data views) directly in the Kibana graphical interface. In the Discover tab when first opened.<br />
        Index patterns: <code>main-app-logs-*</code> and <code>analytics-service-logs-*</code>
      </p>
      <p>
        <strong>Prometheus</strong> (monitoring system and metrics collection) at:
        <a href="http://localhost:9090/query" target="_blank" rel="noopener"
          >http://localhost:9090/query</a
        >
      </p>
      <p>
        <strong>Grafana</strong> (web interface for metrics visualization) at:
        <a href="http://localhost:3001/d/application-metrics/application-metrics-dashboard?orgId=1&from=now-5m&to=now&timezone=browser&refresh=5s" target="_blank" rel="noopener"
          >http://localhost:3001/d/application-metrics/application-metrics-dashboard?orgId=1&from=now-5m&to=now&timezone=browser&refresh=5s</a
        >
        (admin, admin)
      </p>

      <p>
        <strong>PostgreSQL</strong> (connection via any client, e.g. DBeaver):<br />
        IP: <code>localhost:5432</code><br />
        Database: <code>spring_digital_bookstore</code><br />
        Username: <code>admin</code><br />
        Password: <code>admin</code>
      </p>
      <p>
        <strong>Admin credentials in the application</strong>:<br />
        Login: <code>admin@gmail.com</code><br />
        Password: <code>admin</code>
      </p>

      <p>
        Want to learn how Kafka interaction works in this application?
        <a href="kafka.html" target="_blank" rel="noopener">Read detailed description</a>
      </p>

      <ol class="main-steps" start="2">
        <li>
          If you want payment features, ask reviews from users (actually from AI)
          and tech support to work, you need to create a
          <strong>.env</strong> file in the same directory where
          <strong>docker-compose.yml</strong> is located and specify the
          following variables in it, but you will have to obtain the values
          yourself (it's free, but will take an extra 15–20 minutes of your
          time).
        </li>
      </ol>

      <div class="code-block copyable">
        <pre><code># This is how your .env file should look, but the values for these variables should be yours!

OPENAI_API_KEY=sk-proj-...
GEMINI_API_KEY=AIzaSy...

TELEGRAM_BOT_TOKEN=68915...
TELEGRAM_CHAT_ID=14310...</code></pre>
      </div>

      <h2>Instructions for setting up keys and services</h2>

      <h3>1. OpenAI — getting OPENAI_API_KEY</h3>
      <ol>
        <li>
          Go to:
          <a
            href="https://platform.openai.com/settings/organization/api-keys"
            target="_blank"
            rel="noopener"
            >https://platform.openai.com/settings/organization/api-keys</a
          >
        </li>
        <li>Create an organization (if you don't have one yet) at <a href="https://platform.openai.com/settings/organization/general" target="_blank" rel="noopener">https://platform.openai.com/settings/organization/general</a>. Any name will do</li>
        <li>Click <strong>Create new secret key</strong></li>
        <li>Copy the key:</li>
      </ol>
      <div class="code-block">
        <pre><code>OPENAI_API_KEY=sk-proj-...</code></pre>
      </div>
      <h4>For free usage:</h4>
      <ol>
        <li>
          Go to:
          <a
            href="https://platform.openai.com/settings/organization/data-controls/sharing"
            target="_blank"
            rel="noopener"
            >https://platform.openai.com/settings/organization/data-controls/sharing</a
          >
        </li>
        <li>Enable the <strong>Enable for all projects</strong> option</li>
      </ol>

      <h3>2. Gemini — getting GEMINI_API_KEY</h3>
      <ol>
        <li>
          Go to:
          <a
            href="https://aistudio.google.com/app/api-keys"
            target="_blank"
            rel="noopener"
            >https://aistudio.google.com/app/api-keys</a
          >
        </li>
        <li>Create a new key <strong>Create API key</strong></li>
        <li>Copy:</li>
      </ol>
      <div class="code-block">
        <pre><code>GEMINI_API_KEY=AIzaSy...</code></pre>
      </div>
      <p>
        <em
          >Note: Gemini's free quota is very small (about 20 requests per month for the model used in this application)<br />
          If you don't specify GEMINI_API_KEY, "uncensored reviews" won't
          work</em
        >
      </p>

      <h3>3. Telegram — settings for notifications</h3>

      <h4>3.1 Getting TELEGRAM_BOT_TOKEN</h4>
      <ol>
        <li>In Telegram, find <code>@BotFather</code></li>
        <li>Send <code>/newbot</code></li>
        <li>Name the bot</li>
        <li>Copy the token:</li>
      </ol>
      <div class="code-block">
        <pre><code>TELEGRAM_BOT_TOKEN=123456:ABC-DEF...</code></pre>
      </div>

      <h4>3.2 Getting TELEGRAM_CHAT_ID</h4>
      <p>Fastest way:</p>
      <ol>
        <li>In Telegram, find <code>@userinfobot</code></li>
        <li>Send it <code>/start</code></li>
        <li>In the response, it will show your Chat ID</li>
        <li>Paste it into the variable:</li>
      </ol>
      <div class="code-block">
        <pre><code>TELEGRAM_CHAT_ID=123456789</code></pre>
      </div>

      <h3>4. Example of final .env file</h3>
      <div class="code-block">
        <pre><code>OPENAI_API_KEY=sk-proj-...
GEMINI_API_KEY=AIzaSy...

TELEGRAM_BOT_TOKEN=your-telegram-bot-token
TELEGRAM_CHAT_ID=123456789</code></pre>
      </div>
    </div>
  </body>
</html>
