<!DOCTYPE html>
<html lang="ru">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Локальное развертывание - Spring Digital Bookstore</title>
    <link rel="icon" type="image/png" href="../favicon.png" />
    <link rel="stylesheet" href="../assets/styles.css" />
    <script src="../assets/copy-code.js"></script>
  </head>
  <body>
    <div class="language-switcher">
      <a href="../index.html" class="lang-link">Home</a>
      <span class="lang-separator">|</span>
      <a href="local-app.html" class="lang-link active">RU</a>
      <span class="lang-separator">|</span>
      <a href="../en/local-app.html" class="lang-link">EN</a>
    </div>

    <div class="card">
      <h1>Локальное развертывание</h1>
      <ol>
        <li>
          Создай <strong>docker-compose.yml</strong>, скопируй туда данное
          содержимое и запусти командой <code>docker-compose up -d</code>.
        </li>
      </ol>

      <div class="code-block copyable">
        <pre><code>services:
  # Zookeeper для Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: kafka-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - spring-library-network
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 2181 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Kafka Broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-broker
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka-broker:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168 # 7 days
      KAFKA_LOG_SEGMENT_BYTES: 1073741824 # 1GB
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # Memory limit for Kafka (heap memory)
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"
    networks:
      - spring-library-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 120s
    restart: unless-stopped

  # Kafka UI - graphical interface for viewing topics and messages
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      kafka:
        condition: service_started
    ports:
      - "8089:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-broker:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      # Authentication via Basic Auth
      AUTH_TYPE: ${KAFKA_UI_AUTH_TYPE:-BASIC}
      SPRING_SECURITY_USER_NAME: ${KAFKA_UI_USERNAME:-admin}
      SPRING_SECURITY_USER_PASSWORD: ${KAFKA_UI_PASSWORD:-admin}
    networks:
      - spring-library-network
    restart: unless-stopped

  # MailHog - SMTP server for email development and testing
  # Web interface: http://localhost:8025
  # SMTP port: 1025
  mailhog:
    image: mailhog/mailhog:latest
    container_name: mailhog_email_server
    ports:
      - "1025:1025" # SMTP port
      - "8025:8025" # Web UI for viewing emails
    networks:
      - spring-library-network
    restart: unless-stopped

  # Analytics Service
  analytics-service:
    image: 01yura/spring-digital-bookstore-analytics-service:elk
    pull_policy: always
    container_name: analytics-service
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8090:8090"
    environment:
      # Kafka Configuration
      KAFKA_BOOTSTRAP_SERVERS: kafka-broker:29092
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka-broker:29092
      KAFKA_CONSUMER_GROUP_ID: analytics-service-group
      SPRING_KAFKA_CONSUMER_GROUP_ID: analytics-service-group
      # Server Configuration
      SERVER_PORT: 8090
      # Logging
      LOGGING_LEVEL_ROOT: INFO
      LOGGING_LEVEL_ORG_APACHE_KAFKA: WARN
      LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_KAFKA: INFO
      LOGGING_LEVEL_ONLINE_ITYURA_ANALYTICS: INFO
      # Aggregation interval
      ANALYTICS_AGGREGATION_INTERVAL_MS: ${ANALYTICS_AGGREGATION_INTERVAL_MS:-60000}
      # ELK Stack settings for sending logs to Logstash
      LOGSTASH_HOST: logstash
      LOGSTASH_PORT: 5000
      LOGSTASH_ENABLED: "true"
    networks:
      - spring-library-network
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:8090/api/analytics/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # React UI application
  ui:
    image: 01yura/spring-digital-library-ui:with_analytics_and_email_without_https_for_local_run
    pull_policy: always
    container_name: spring-digital-bookstore-ui
    ports:
      - "80:80"
    networks:
      - spring-library-network
    depends_on:
      - backend
    restart: unless-stopped

  # PostgreSQL database for local deployment
  postgres:
    image: postgres:16-alpine
    container_name: spring-digital-library-db
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-spring_digital_bookstore}
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-admin}
    ports:
      - "5432:5432"
    volumes:
      # Database data storage on host (for Windows use format C:/path/to/dir)
      - ${POSTGRES_DATA_PATH:-C:/spring-digital-bookstore/postgres_data}:/var/lib/postgresql/data
    networks:
      - spring-library-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d spring_digital_bookstore"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Spring Boot application for local deployment without HTTPS
  backend:
    image: 01yura/spring-digital-bookstore:elk
    pull_policy: always
    container_name: spring-digital-bookstore-app
    environment:
      # Database connection settings
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB:-spring_digital_bookstore}
      SPRING_DATASOURCE_USERNAME: ${SPRING_DATASOURCE_USERNAME:-admin}
      SPRING_DATASOURCE_PASSWORD: ${SPRING_DATASOURCE_PASSWORD:-admin}

      # JPA/Hibernate settings
      SPRING_JPA_DATABASE_PLATFORM: ${SPRING_JPA_DATABASE_PLATFORM:-org.hibernate.dialect.PostgreSQLDialect}
      SPRING_JPA_HIBERNATE_DDL_AUTO: ${SPRING_JPA_HIBERNATE_DDL_AUTO:-update}
      SPRING_JPA_SHOW_SQL: ${SPRING_JPA_SHOW_SQL:-false}
      SPRING_JPA_PROPERTIES_HIBERNATE_FORMAT_SQL: ${SPRING_JPA_PROPERTIES_HIBERNATE_FORMAT_SQL:-true}

      # JWT settings
      JWT_SECRET: ${JWT_SECRET:-my-secret-key-for-jwt-generation}
      JWT_EXPIRATION: ${JWT_EXPIRATION:-300000}
      JWT_REFRESH_EXPIRATION: ${JWT_REFRESH_EXPIRATION:-86400000}

      # Swagger/OpenAPI settings
      SPRINGDOC_API_DOCS_PATH: ${SPRINGDOC_API_DOCS_PATH:-/v3/api-docs}
      SPRINGDOC_SWAGGER_UI_PATH: ${SPRINGDOC_SWAGGER_UI_PATH:-/swagger-ui.html}
      SPRINGDOC_SWAGGER_UI_OPERATIONS_SORTER: ${SPRINGDOC_SWAGGER_UI_OPERATIONS_SORTER:-method}
      SPRINGDOC_SWAGGER_UI_TAGS_SORTER: ${SPRINGDOC_SWAGGER_UI_TAGS_SORTER:-alpha}

      # JVM settings
      JAVA_OPTS: ${JAVA_OPTS:--Xmx512m -Xms512m}

      # Path for storing book images (fixed inside container)
      APP_IMAGES_STORAGE_PATH: /opt/spring-digital-bookstore/pictures
      # Path for storing book PDF files (fixed inside container)
      APP_PDF_STORAGE_PATH: /opt/spring-digital-bookstore/pdf

      # Frontend URL for redirect after payment
      FRONTEND_URL: ${FRONTEND_URL:-http://localhost}

      # Stripe settings
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY:-sk_test_51Sn9eKF06mQasm4mhBSG71Wes6rz09BTuQicIu37oRIw5agFgZuGMGZQk4IeftRm2aQGJXFma5IPwm1iT77WlALs00VDZNJkEL}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET:-test-value}
      STRIPE_SUCCESS_URL: ${STRIPE_SUCCESS_URL:-http://localhost/api/v1/payment/success}
      STRIPE_CANCEL_URL: ${STRIPE_CANCEL_URL:-http://localhost/api/v1/payment/cancel}

      # OpenAI API settings
      OPENAI_API_KEY: ${OPENAI_API_KEY:-test-value}

      # Gemini API settings
      GEMINI_API_KEY: ${GEMINI_API_KEY:-test-value}

      # Kafka Configuration for sending events
      KAFKA_BOOTSTRAP_SERVERS: kafka-broker:29092
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka-broker:29092

      # Telegram settings for sending messages to Telegram Bot
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN:-test-value}
      TELEGRAM_CHAT_ID: ${TELEGRAM_CHAT_ID:-test-value}

      # SMTP settings for sending email via MailHog
      SPRING_MAIL_HOST: mailhog
      SPRING_MAIL_PORT: 1025
      SPRING_MAIL_USERNAME: ${SPRING_MAIL_USERNAME:-}
      SPRING_MAIL_PASSWORD: ${SPRING_MAIL_PASSWORD:-}
      SPRING_MAIL_SMTP_AUTH: ${SPRING_MAIL_SMTP_AUTH:-false}
      SPRING_MAIL_SMTP_STARTTLS_ENABLE: ${SPRING_MAIL_SMTP_STARTTLS_ENABLE:-false}
      SPRING_MAIL_SMTP_SSL_ENABLE: ${SPRING_MAIL_SMTP_SSL_ENABLE:-false}
      SPRING_MAIL_FROM: ${SPRING_MAIL_FROM:-noreply@localhost}

      # Base URL for email verification links (must match the port where backend is available)
      APP_EMAIL_VERIFICATION_BASE_URL: ${APP_EMAIL_VERIFICATION_BASE_URL:-http://localhost}

      # ELK Stack settings for sending logs to Logstash
      LOGSTASH_HOST: logstash
      LOGSTASH_PORT: 5000

      # Enable/disable Logstash (disabled by default in application.properties)
      LOGSTASH_ENABLED: "true"
      # Enable/disable Kafka (disabled by default in application.properties)
      KAFKA_ENABLED: "true"

    ports:
      - "8088:8080"
    volumes:
      # Storing book images in regular directory on host (for Windows use format C:/path/to/dir)
      - ${APP_IMAGES_STORAGE_PATH:-C:/spring-digital-bookstore/pictures}:/opt/spring-digital-bookstore/pictures
      # Storing book PDF files in regular directory on host (for Windows use format C:/path/to/dir)
      - ${APP_PDF_STORAGE_PATH:-C:/spring-digital-bookstore/pdf}:/opt/spring-digital-bookstore/pdf
    networks:
      - spring-library-network
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      mailhog:
        condition: service_started
    restart: unless-stopped

  # Elasticsearch for storing logs
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      # Increase memory to 1GB for stable operation
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      # Disable memory_lock for Windows/Docker (may not work)
      - bootstrap.memory_lock=false
      # Settings for faster operation in dev environment
      - action.auto_create_index=true
      - cluster.routing.allocation.disk.threshold_enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - ${ELASTICSEARCH_DATA_PATH:-C:/spring-digital-bookstore/elasticsearch_data}:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - spring-library-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -f http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=30s || exit 1",
        ]
      interval: 30s
      timeout: 30s
      retries: 10
      start_period: 120s
    restart: unless-stopped

  # Logstash for receiving and processing logs
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - "5000:5000"
      - "5044:5044"
      - "9600:9600"
    environment:
      - "LS_JAVA_OPTS=-Xmx256m -Xms256m"
    command:
      - /bin/bash
      - -c
      - |
        mkdir -p /usr/share/logstash/pipeline /usr/share/logstash/config
        cat > /usr/share/logstash/config/pipelines.yml << 'PIPELINES_EOF'
        # Pipeline configuration for Logstash
        - pipeline.id: main
          path.config: "/usr/share/logstash/pipeline/logstash.conf"
        PIPELINES_EOF
        cat > /usr/share/logstash/config/logstash.yml << 'LOGSTASH_EOF'
        http.host: "0.0.0.0"
        xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch:9200" ]
        LOGSTASH_EOF
        cat > /usr/share/logstash/pipeline/logstash.conf << 'LOGCONF_EOF'
        input {
          tcp {
            port => 5000
            codec => json_lines
          }
        }

        filter {
          # logstash-logback-encoder sends JSON directly via TCP with json_lines codec
          # All fields are already directly available (level, message, service, @timestamp, logger_name, thread_name, etc.)
          
          # Adding metadata for indexing based on service field
          mutate {
            add_field => { "[@metadata][index]" => "%{service}-logs-%{+YYYY.MM.dd}" }
          }
          
          # If service is not defined, use default value
          if ![service] {
            mutate {
              add_field => { "service" => "unknown" }
            }
          }
          
          # Filtering sensitive data (passwords, tokens)
          # Uncomment if you need to mask sensitive data
          # mutate {
          #   gsub => [
          #     "message", "(?i)(password|token|secret|key|api[_-]?key)=[^&\s\"']+", "\1=***",
          #     "message", "(?i)(\"password\"\\s*:\\s*\")([^\"]+)(\")", "\1***\3",
          #     "message", "(?i)(\"token\"\\s*:\\s*\")([^\"]+)(\")", "\1***\3"
          #   ]
          # }
        }

        output {
          elasticsearch {
            hosts => ["elasticsearch:9200"]
            # Dynamic index based on service field
            index => "%{[@metadata][index]}"
            # Or you can use fixed indices:
            # index => "%{service}-logs-%{+YYYY.MM.dd}"
          }
          
          # Fallback to stdout for debugging (optional, can be commented out in production)
          stdout {
            codec => rubydebug
          }
        }
        LOGCONF_EOF
        exec /usr/local/bin/docker-entrypoint
    networks:
      - spring-library-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9600/_node/stats || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      # Increase timeouts for index creation
      - ELASTICSEARCH_REQUEST_TIMEOUT=120000
      # Settings for faster startup
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=changeme-changeme-changeme-changeme
      - XPACK_REPORTING_ENCRYPTIONKEY=changeme-changeme-changeme-changeme
      - XPACK_SECURITY_ENCRYPTIONKEY=changeme-changeme-changeme-changeme
    networks:
      - spring-library-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 300s
    restart: unless-stopped

networks:
  spring-library-network:
    driver: bridge
</code></pre>
      </div>
      <p>
        <strong>Фронтенд</strong> будет доступен по адресу
        <a href="http://localhost" target="_blank" rel="noopener"
          >http://localhost</a
        >
      </p>
      <p>
        <strong>Swagger</strong> по адресу
        <a
          href="http://localhost:8088/swagger-ui/index.html"
          target="_blank"
          rel="noopener"
          >http://localhost:8088/swagger-ui/index.html</a
        >
      </p>
      <p>
        <strong>Kafka UI</strong> по адресу:
        <a href="http://localhost:8089" target="_blank" rel="noopener"
          >http://localhost:8089</a
        >
        (admin, admin)
      </p>
      <p>
        <strong>MailHog</strong> (веб-интерфейс для просмотра отправленных email и подтверждения регистрации) по адресу:
        <a href="http://localhost:8025" target="_blank" rel="noopener"
          >http://localhost:8025</a
        >
      </p>
        <strong>Kibana</strong> (веб-интерфейс для просмотра логов) по адресу:
        <a href="http://localhost:5601" target="_blank" rel="noopener"
          >http://localhost:5601</a
        ><br />
        Для отображения логов в Kibana необходимо прописать индексы (создать так называемые Data views) прямо в графическом интерфейсе Kibana. Во вкладке Discover при первом включении.</br>
        Паттерн для индексов: <code>main-app-logs-*</code> и <code>analytics-service-logs-*</code>
      </p>

      <h2>Credentials администратора в самом приложении</h2>
      <ul>
        <li><strong>Логин</strong>: <code>admin@gmail.com</code></li>
        <li><strong>Пароль</strong>: <code>admin</code></li>
      </ul>

      <h2>Подключение к базе PostgreSQL через любой клиент (н-р: DBeaver)</h2>
      <ul>
        <li><strong>IP</strong>: <code>localhost:5432</code></li>
        <li>
          <strong>Database</strong>: <code>spring_digital_bookstore</code>
        </li>
        <li><strong>Username</strong>: <code>admin</code></li>
        <li><strong>Password</strong>: <code>admin</code></li>
      </ul>

      <p>
        Хотите узнать как работает взаимодействие через Kafka в этом приложении?
        <a href="kafka.html" target="_blank" rel="noopener">Читайте подробное описание</a>
      </p>

      <p>
        2. Если хотите чтобы работали функции запроса отзыва о книге у
        пользователя (по факту у AI) и техподдержка, то необходимо создать в той
        же директории где лежит
        <strong>docker-compose.yml</strong> еще файл <strong>.env</strong> и
        прописать в нем следующие переменные, но значения вам придется получить
        самим (это бесплатно, но придется потратить лишних 15-20 минут вашего
        времени):
      </p>

      <div class="code-block copyable">
        <pre><code># Вот так должен выглядеть ваш .env файл, но значения для данных переменных должны быть ваши!

OPENAI_API_KEY=sk-proj-...
GEMINI_API_KEY=AIzaSy...

TELEGRAM_BOT_TOKEN=68915...
TELEGRAM_CHAT_ID=14310...</code></pre>
      </div>

      <h2>Инструкция по получению токенов, API ключей и прочей лабуды для разных сервисов</h2>

      <h3>1. OpenAI — получение OPENAI_API_KEY</h3>
      <ol>
        <li>
          Перейдите на:
          <a
            href="https://platform.openai.com/settings/organization/api-keys"
            target="_blank"
            rel="noopener"
            >https://platform.openai.com/settings/organization/api-keys</a
          >
        </li>
        <li>Создайте организацию (если ещё нет) на <a href="https://platform.openai.com/settings/organization/general" target="_blank" rel="noopener">https://platform.openai.com/settings/organization/general</a>. Имя любое</li>
        <li>Нажмите <strong>Create new secret key</strong></li>
        <li>Скопируйте ключ:</li>
      </ol>
      <div class="code-block">
        <pre><code>OPENAI_API_KEY=sk-proj-...</code></pre>
      </div>
      <h4>Для бесплатного использования:</h4>
      <ol>
        <li>
          Перейдите:
          <a
            href="https://platform.openai.com/settings/organization/data-controls/sharing"
            target="_blank"
            rel="noopener"
            >https://platform.openai.com/settings/organization/data-controls/sharing</a
          >
        </li>
        <li>Включите опцию <strong>Enable for all projects</strong></li>
      </ol>

      <h3>2. Gemini — получение GEMINI_API_KEY</h3>
      <ol>
        <li>
          Перейдите:
          <a
            href="https://aistudio.google.com/app/api-keys"
            target="_blank"
            rel="noopener"
            >https://aistudio.google.com/app/api-keys</a
          >
        </li>
        <li>Создайте новый ключ <strong>Create API key</strong></li>
        <li>Скопируйте:</li>
      </ol>
      <div class="code-block">
        <pre><code>GEMINI_API_KEY=AIzaSy...</code></pre>
      </div>
      <p>
        <em
          >Примечание: Бесплатная квота у Gemini очень мала (вроде 20 запросов в месяц для модели, которая используется в этом приложении)<br />
          Если не указать GEMINI_API_KEY, то "отзывы без цензуры" работать не будут</em
        >
      </p>

      <h3>3. Telegram — настройки для уведомлений</h3>

      <h4>3.1 Получение TELEGRAM_BOT_TOKEN</h4>
      <ol>
        <li>В Telegram найдите <code>@BotFather</code></li>
        <li>Отправьте <code>/newbot</code></li>
        <li>Назовите бота</li>
        <li>Скопируйте токен:</li>
      </ol>
      <div class="code-block">
        <pre><code>TELEGRAM_BOT_TOKEN=123456:ABC-DEF...</code></pre>
      </div>

      <h4>3.2 Получение TELEGRAM_CHAT_ID</h4>
      <p>Быстрее всего через:</p>
      <ol>
        <li>В Telegram найдите <code>@userinfobot</code></li>
        <li>Напишите ему /start</li>
        <li>В ответе он покажет ваш Chat ID</li>
        <li>Вставьте в переменную:</li>
      </ol>
      <div class="code-block">
        <pre><code>TELEGRAM_CHAT_ID=123456789</code></pre>
      </div>

      <h3>4. Пример итогового .env файла</h3>
      <div class="code-block">
        <pre><code>
OPENAI_API_KEY=sk-proj-...
GEMINI_API_KEY=AIzaSy...

TELEGRAM_BOT_TOKEN=123456:ABC-DEF...
TELEGRAM_CHAT_ID=123456789</code></pre>
      </div>
    </div>
  </body>
</html>
